---
title: "Week 2. More Git + Better Coding Practices"
output:
  html_document:
    toc: true
    include:
      after_body: footer.html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(kableExtra)
dt <- data.frame("Compartmentalized", "Documented", "Extendible", "Reproducible", "Robust")
kable(dt, col.names=NULL) %>%
  kable_styling(full_width = TRUE) %>%
  row_spec(1, bold = FALSE, color = "white", background = "blue") %>%
  column_spec(column = 1:5, width = "20%")
```


# Overview

This week I will cover more Git topics and basic coding habits that I have learned over the years. These are good habits that will help make your code less buggy and easier to extend.

Git, GitHub, GitLab

* How to clone someone else's GitHub or GitLab repository
* How to clone your own repository--when you want to make a copy and use that as a template for something new.
* What are branches, merge conflicts and pull requests?
* Fork or clone? What's the difference?
* How to add Git to an existing RStudio project and get that on GitHub or GitLab.

Coding Tips

* How to organize and plan your code and why adopting an 'object-oriented mindset' will help your code organization (regardless of whether you use object-oriented coding)
* What are namespaces and why you should use `::` to call functions.
* Tips on writing code and functions in R - little things that will make your code better and more robust
* Tips on things to avoid in your R code, i.e. quirks of R that will tend to create bugs

# Code Organization

## R is object oriented

Run this code.

```{r}
fit <- lm(dist ~ speed, data=cars)
class(fit)
```

"lm" is the class of the object "fit". R *knows* things to do with objects of class "lm".

```{r}
coef(fit)
```

It did that because there is a function `coef.lm` and R looks for that to see what to do when you pass a "lm" object to `coef()`.

All object of class "lm" are a list with a standard set of items in that list:

```{r}
names(fit)
```

That information contains all the information about the fit, the data used for the fit, and the call to `lm()`. We can just pass `fit` to `print()`, `plot()`, `summary()`, etc. I could write a new function, `foo.lm`, to do something new with a "lm" object. 

In the call to `lm`, we had another object, `saldat`. `saldat` is class `data.frame`. `lm()` knows what to do with data that is a data frame.

## Object-oriented mindset

Let's look at [salmon.R](salmon.html). What sort of elements are in this script?

* data
* fits
* predictions
* plots

But the elements are not like "objects". One data set is a data frame with column headings year, wild, flow, temp and the other is a matrix with years as column headings. The fits are all different types and some have no info about what years or data I fit to (see e.g. `fit3`). The plots have to be tweaked based on the data and the fits.

Instead we would like to work with "objects" that have a consistent format and have all the information needed for functions that use those objects.


```{r out.width=500, echo=FALSE}
# All defaults
knitr::include_graphics("images/code-org.png")
```



## An object

* **Has a standardized form** (you can describe what elements it needs to have)
* Has all the information that subsequent functions might need to use this object.
* Has information so you know how this object was made

## How on earth is one supposed to do this?

*...if it is even worthwhile, which I'm not so sure about...*

This is part of code organization. Time put into planning and standardizing your code will make you much more efficient (even if it takes time in the beginning) and will definitely help prevent errors and bugs in your code. A big coding project requires this way of thinking.

## How do get started

1. Do a little planning on a piece of paper. Example, **data**:

![data planning](images/data-planning.jpg)

1. Then start putting your script in to categories (data, fitting, plotting). Look at [salmon.R](salmon.html)

2. Write functions instead of long scripts.

Like `read_data()`, `fit_model()`, `plot1()`. This will naturally lead you towards "object-oriented" thinking.

You do not want to be duplicating your code, e.g. lines of code that fit a model or plot, over and over. You'll just introduce impossible to find errors when you decide to change how you are fitting the data.

3. Have your functions output both the "thing" + the info about that:

```
read_data <- function(fil, notes=NULL){
  dat <- read.csv(fil)
  ... bunch of code to fix up the data ...
  if(stringr::str_detect(fil, "Chinook")) species <- "Chinook"
  if(stringr::str_detect(fil, "Coho")) species <- "Coho"
  meta=list(
    file=fil,
    call=deparse( sys.call() ),
    date=Sys.time(),
    notes=notes,
    species=species,
    min.year=min(dat$year),
    max.year=max(dat$year) )
  obj <- list(meta=meta, data=dat)
  return(obj)
}
```

4. Using a few standardized (say plotting) functions will force you to move towards "object-oriented" thinking. So as opposed to copying lines of plotting code over and over when you need a plot like that.

For example, a script:

```{r}
par(mfrow=c(1,2))
a <- data.frame(year=2000:2009, x=1:10)
plot(a$year, a$x, xlab="year", ylab="count", ylim=c(0,100), xlim=c(1980,2010))

b <- data.frame(YEAR=1980:2009, count=1:30+50)
plot(b$YEAR, b$count, xlab="year", ylab="count", ylim=c(0,100), xlim=c(1980,2010))
```


Versus writing a function and standardizing the data frames. This is a toy example.

```{r}
plot1 <- function(x, xlims=c(1980,2010), ylims=c(0,10)){
  plot(x$year, x$x, xlab="year", ylab="count", ylim=ylims, xlim=xlims)
}

par(mfrow=c(1,2))
a <- data.frame(year=2000:2009, x=1:10)
b <- data.frame(year=1980:2009, x=1:30+50)
ylims <- c(min(a$x,b$x), max(a$x,b$x))
plot1(a, ylims=ylims)
plot1(b, ylims=ylims)
```

5. Sketch out the functions that you need to write. You'll update this as you go along.


Next step for object-oriented programming: Weeks 4 and 5 will go into how to assemble your code into an R package and I'll talk about creating formal objects and methods (like print, plot) for those objects.

# Namespaces

* Namespaces. Every function in R belongs to a package. You can be 100% explicit in your function calls by using `::`. So `forecast::forecast()` would specify the `forecast` function in the **forecast** package. Why use this?

1. **Show what package the function comes from**

```{r}
?dismo
?dismo::dismo
```

2. You won't run into the problem where code fails because you forgot to do `library(package)` or `require(package)`.
3. You won't run into problem where you have functions with the same name in two different packages or you accidentally give your function the same name as the function in a package that you need.

Disastrous things that happen to your code when you don't use Namespaces.

```{r}
auto.arima <- function(x){x}
library(forecast)
auto.arima(1:10)
```

```{r}
rm(auto.arima)
auto.arima(1:10)
```

I use `::` for cases where I only need a few functions from that package OR when I am writing an R package (because it is required for me to do this).

# Various Tips and Quirks of R

1. Do not hard code any variables into your scripts or code. Ok. The reality is, you will. Try to hard code **less**. The more you avoid hard-coding, the faster you will be.

Not this
```{r}
x <- 1
for(i in 1:10) x <- c(x, 2*i)
```

but this

```{r}
n <- 10
w <- 2
x <- 1
for(i in 1:n) x <- c(x, w*i)
```


1. Your working directory environment is your enemy (for bugs at least). You will have to keep it clean `rm(list=ls())`, use Rmarkdown files to run code (because that uses a clean environment), or assemble your code into an R package. 

*All R coders forget this periodically and have wasted significant hours debugging due to a variable left in the environment.*

1. Use `class()` to figure out what R thinks an objects class is. The class of an object determines many things about how R functions respond to an object.

1. Data frames are lists not matrices.  Sadly R does not tell you this.

```{r, error=TRUE}
a <- data.frame(a=1:10, b=1:10, c=1:10)
t(a[,1:2])
a[,1:2]%*%t(a[,1:2])
```

Doesn't work because `a` is not a matrix not matter how it looks like one.
```{r}
class(a[,1:2])
class(a[[1]])
class(a[1])
class(unlist(a))
unlist(lapply(a, length))
```

1. Factors (in data frames) is cause of much trouble. You can avoid with 
```{r}
a <- data.frame(a=1:10, b=letters[1:10], stringsAsFactors=FALSE)
unlist(lapply(a,class))
a <- data.frame(a=1:10, b=letters[1:10])
unlist(lapply(a,class))
```

Figuring out when you need a character to be a "factor" and when you need it to be a "character" will lead to much suffering, but with time, you'll figure it out. Remember, `class()` is your friend.

1. R "helps" you changing class on your objects...**silently**. This will cause a frightful number of mysterious bugs and errors.

```{r}
a <- data.frame(a=1:10, b=letters[1:10], stringsAsFactors=FALSE)
apply(a, 2, function(x){x[1:2]})
```
What just happened? `apply` needs a matrix, so R *silently* turned your data frame into a matrix. In a matrix all elements need to be the same class. So in this case it made everything a character.

```{r error=TRUE}
a <- matrix(1, 3, 3)
apply(a, 2, mean)
apply(a[,1:2], 2, mean)
apply(a[,1], 2, mean)

class(a)
class(a[,1])
class(a[,1,drop=FALSE])
```

1. Use `FALSE` and `TRUE` instead of `F` and `T`

```{r error=TRUE}
T==1
T <- 1:10
T==1
TRUE=1:10
```

```{r}
rm(T)
```

1. You can overwrite most any function in R. Like `plot()`!!

```{r}
plot <- function(x){cat("Yelp!")}
plot(1:10)
graphics::plot(1:10)
```
```{r}
rm(plot)
```

1. You could spend 2-3 hours figuring out how to use `tapply()` or **dplyr** to do a task, or just use a `for` loop.

1. [Piping](https://r4ds.had.co.nz/pipes.html) means compact code, less memory consumption.... and can be terribly slow computationally. Avoid in simulations.

What's piping? It's a function in the **magrittr** that allows you to strings operations together.

```{r}
library(magrittr)
rnorm(100) %>%
  matrix(ncol = 2) %>%
  apply(2,mean)
```

1. Gravitate towards a standard coding style. Don't make one up. Use a standard one. I use mainly the [tidyverse style guide](https://style.tidyverse.org/) (or I try). There is a package called **styler** that has a RStudio plugin that makes it easy to restyle all your code.

1. Gravitate towards a standardized data format. It's easier to reuse your plotting functions (and others) if you do that. I use a format similar to [tidy data](https://r4ds.had.co.nz/tidy-data.html) to data in data frames.

1. Gravitate towards a standardized names for things you use in your code consistently. Using `alpha`, `alp`, `Alpha`, `a` for the same thing in different coding projects make re-using code much slower.

1. Use the **here** package along with `file.path()` to avoid hard-wired directory names. This will properly construct file paths for whatever Os you are on.  Use RStudio project feature to get you to the right working directory.

```{r}
#setwd('~/GitHub/RWorkflow-NWFSC-2020/')
fil <- file.path(here::here(), "data", "salmon.R")
fil
```


# Week 3

Brief summary of some debugging tools in R and RStudio + mostly RMarkdown.

* debugging functions
* bench-marking
* profiling

